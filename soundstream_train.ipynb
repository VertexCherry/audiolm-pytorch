{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n337KoD2om3L",
    "outputId": "97ada0c6-f21c-483e-d63d-08abddd49004"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Jul 29 18:45:40 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.86.01              Driver Version: 536.67       CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4070 Ti     On  | 00000000:2D:00.0  On |                  N/A |\n",
      "|  0%   43C    P5              19W / 285W |   1295MiB / 12282MiB |     10%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A        23      G   /Xwayland                                 N/A      |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/audiolm/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-07-29 18:45:42 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
      "2023-07-29 18:45:42 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "\n",
    "# imports\n",
    "import math\n",
    "import wave\n",
    "import struct\n",
    "import os\n",
    "import urllib.request\n",
    "import tarfile\n",
    "import random\n",
    "from audiolm_pytorch import SoundStream, SoundStreamTrainer, HubertWithKmeans, SemanticTransformer, SemanticTransformerTrainer, HubertWithKmeans, CoarseTransformer, CoarseTransformerWrapper, CoarseTransformerTrainer, FineTransformer, FineTransformerWrapper, FineTransformerTrainer, AudioLM\n",
    "from torch import nn\n",
    "import torch\n",
    "import torchaudio\n",
    "from random import shuffle\n",
    "from fs.osfs import OSFS\n",
    "from fs.mountfs import MountFS\n",
    "from fs import open_fs\n",
    "\n",
    "sample_rate = 16000\n",
    "\n",
    "# define all dataset paths, checkpoints, etc\n",
    "dataset_folder = \"placeholder_dataset\"\n",
    "soundstream_ckpt = \"results/soundstream.8.pt\" # this can change depending on number of steps\n",
    "hubert_ckpt = 'hubert/hubert_base_ls960.pt'\n",
    "hubert_quantizer = f'hubert/hubert_base_ls960_L9_km500.bin' # listed in row \"HuBERT Base (~95M params)\", column Quantizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from IPython.display import Audio\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_waveform(waveform, sample_rate, title=\"Waveform\", xlim=None):\n",
    "    waveform = waveform.numpy()\n",
    "\n",
    "    num_channels, num_frames = waveform.shape\n",
    "    time_axis = torch.arange(0, num_frames) / sample_rate\n",
    "\n",
    "    figure, axes = plt.subplots(num_channels, 1)\n",
    "    if num_channels == 1:\n",
    "        axes = [axes]\n",
    "    for c in range(num_channels):\n",
    "        axes[c].plot(time_axis, waveform[c], linewidth=1)\n",
    "        axes[c].grid(True)\n",
    "        if num_channels > 1:\n",
    "            axes[c].set_ylabel(f\"Channel {c+1}\")\n",
    "        if xlim:\n",
    "            axes[c].set_xlim(xlim)\n",
    "    figure.suptitle(title)\n",
    "    plt.show(block=False)\n",
    "    \n",
    "def plot_specgram(waveform, sample_rate, title=\"Spectrogram\", xlim=None):\n",
    "    waveform = waveform.numpy()\n",
    "\n",
    "    num_channels, _ = waveform.shape\n",
    "\n",
    "    figure, axes = plt.subplots(num_channels, 1)\n",
    "    if num_channels == 1:\n",
    "        axes = [axes]\n",
    "    for c in range(num_channels):\n",
    "        axes[c].specgram(waveform[c], Fs=sample_rate)\n",
    "        if num_channels > 1:\n",
    "            axes[c].set_ylabel(f\"Channel {c+1}\")\n",
    "        if xlim:\n",
    "            axes[c].set_xlim(xlim)\n",
    "    figure.suptitle(title)\n",
    "    plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Psychostream-01/44536bb07723119c07d04f9732220c01.train.5.mp3', '/Jamendo-01/090c64401a83942711bb3da6f94a2301.train.3.mp3', '/Psychostream-01/3d2d9aa22842c848c7c56648d3c46501.train.0.mp3', '/Psychostream-01/dd5c2e5f150031711f8024783fe7e501.train.0.mp3', '/Jamendo-01/d3c405a0e58c6cbcf4d5c7b92c22e401.train.15.mp3', '/Psychostream-00/6619abba734e8b4d43363ab493d7b300.train.11.mp3', '/Psychostream-01/e1bc8ff1fc6b10e3d6ee42dbae2a1601.train.6.mp3', '/Psychostream-01/c9becafffb917ea5297feb4e68c1d001.train.6.mp3', '/Psychostream-00/51aec0af93441fa6cf9e56f143646a00.train.4.mp3', '/Psychostream-00/7c68aec79306b285ff3d14d7e337d900.train.0.mp3', '/Psychostream-01/6549304a3911a6b35ec43f578a8f7d01.train.1.mp3', '/Jamendo-00/8ac545fc1ed40fd620851fd457869c00.train.5.mp3', '/Psychostream-01/628fe96d3033cd2ac1fd47b792f94201.train.8.mp3', '/Psychostream-00/8aa60049d98222ccf7e9eae7108b7000.train.0.mp3', '/Jamendo-00/d74846b8190cad0912ffd05a02e75000.train.8.mp3', '/Psychostream-00/f090002461c0d9dd3f482b6fc1ef0500.train.3.mp3', '/Jamendo-01/c1420a8551bd403bcb02eea2cf68cd01.train.5.mp3', '/Psychostream-01/e853e6dd766e59fe47fcc71747354b01.train.0.mp3', '/Jamendo-01/30179930a466b50344c1185c0252fb01.train.3.mp3', '/Jamendo-00/d5469e0fa755d7248f3705b862d9da00.train.9.mp3', '/Psychostream-00/31328de9045dc32fe4c6df479cb96f00.train.13.mp3', '/dns4-read/chetvero_nischih_s000772_seg_0.mp3', '/Psychostream-00/b26149272855baa2bd75bbfc3205be00.train.2.mp3', '/Psychostream-01/57e0b9047a337ff809602843a997ae01.train.10.mp3', '/Psychostream-01/8fcd1a39c3d3a996d752e0c045092101.train.8.mp3', '/Psychostream-01/e7c11cd2c75209a0299c09a747fc8a01.train.1.mp3', '/Jamendo-00/ec5226131f0010e9352768a4d16d3500.train.11.mp3', '/Psychostream-01/e83c46c59cfb16e0644df80bb3634201.train.12.mp3', '/Psychostream-00/c81c72aa60895b8007358f7b2b224b00.train.11.mp3', '/Psychostream-00/cb5b755dde538f1570100aabf0179e00.train.4.mp3', '/Psychostream-00/07d4300dc32445d42a9b6fd96623e100.train.10.mp3', '/Psychostream-00/f92108ddc46892e46914cfbda5a71f00.train.2.mp3', '/Psychostream-01/3dedec0f0ee95ba2ea38c157cd3e9601.train.9.mp3', '/Psychostream-01/62cf6e6b04600a3178207712a5a9f901.train.0.mp3', '/Psychostream-00/eff30b02832dfcefd2a6323922fef500.train.2.mp3', '/Psychostream-01/16c2167153be4cb70a14c073a2a27801.train.11.mp3', '/dns4-read/chetvero_nischih_s000240.mp3', '/Jamendo-00/c9b19969e3398a53971f7e049ab19500.train.2.mp3', '/Psychostream-00/4a2106b717a2328f220d3f28cc6cdd00.train.4.mp3', '/Jamendo-00/e5a42d5ed711e39ae81f1b3f3efe0400.train.2.mp3', '/Psychostream-01/16dcac4247a8d5e2a9c150c962e4e401.train.7.mp3', '/Jamendo-01/e435b946dae13c043e5a067b8cfed901.train.5.mp3', '/Psychostream-01/3b68b83ac8f70c42c2175bc2ba3d9201.train.3.mp3', '/Psychostream-01/2704dce146922d7c002841f46ee98b01.train.3.mp3', '/Psychostream-00/d969c8ad27547d42cd5235bb48bc7e00.train.0.mp3', '/Jamendo-01/db26f7208a11423cd5c07a3b7c8f9501.train.12.mp3', '/Psychostream-00/987bb52ee5eed3b64f511b99f4a93b00.train.0.mp3', '/Psychostream-00/54db19d4a1be901e41ea380293d5dd00.train.4.mp3', '/Psychostream-01/b9e7123a94630f41b6c8c45fca8d3f01.train.8.mp3', '/Psychostream-00/13b5fdde2bde4203f51be8b27accfb00.train.1.mp3']\n"
     ]
    }
   ],
   "source": [
    "# Setup filesystem\n",
    "dataset_fs = MountFS()\n",
    "\n",
    "#dataset_fs.mount('dns4-read', open_fs('s3://music-clip-dataset/dns/clean-fullband/read_speech/'))\n",
    "dataset_fs.mount('dns4-read', open_fs('s3://music-clip-dataset/dns/clean-fullband/russian/M-AILABS_Speech_Dataset/ru_RU_47hrs_48k/female/hajdurova/chetvero_nischih/wavs/'))\n",
    "[dataset_fs.mount(f'Jamendo-{_:02x}', open_fs(f's3://music-clip-dataset/clips/train/{_:02x}/')) for _ in range(2)]\n",
    "[dataset_fs.mount(f'Psychostream-{_:02x}', open_fs(f's3://music-clip-dataset/psychostream/train/{_:02x}/')) for _ in range(2)]\n",
    "#dataset_fs.add_fs('dns4-read', open_fs('s3://music-clip-dataset/dns/clean-fullband/read_speech/'))\n",
    "\n",
    "# Get all music files and shuffle them\n",
    "music_files = []\n",
    "for path in dataset_fs.walk.files(filter=['*.mp3']):\n",
    "    music_files.append(path)\n",
    "    #print(path)\n",
    "random.shuffle(music_files)\n",
    "print(music_files[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "jwYCbFpHvmRI"
   },
   "outputs": [],
   "source": [
    "from email.mime import audio\n",
    "from io import BytesIO\n",
    "import os\n",
    "import random\n",
    "import itertools\n",
    "from einops import rearrange\n",
    "import fs.info\n",
    "from torchaudio.functional import resample\n",
    "from torch import Tensor\n",
    "import torch.nn.functional as F\n",
    "from audiolm_pytorch.soundstream import cast_tuple\n",
    "from audiolm_pytorch.utils import curtail_to_multiple\n",
    "\n",
    "class SeabassIterableDataset(torch.utils.data.IterableDataset):\n",
    "    def __init__(self, start, end, files: list[str], fs: MountFS, effects, clip_len:float = 2.0, tick_char='.', sample_rate=16000):\n",
    "        super(SeabassIterableDataset).__init__()\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "        self.effects = effects\n",
    "        self.files = files\n",
    "        self.fs = fs\n",
    "        self.clip_len = clip_len\n",
    "        self.tick_char = tick_char\n",
    "        self.sample_rate = sample_rate\n",
    "\n",
    "    def getSample(self, index):\n",
    "        global sample_rate\n",
    "        \n",
    "        filename = self.files[index]\n",
    "        #data = BytesIO(self.fs.readbytes(filename))\n",
    "        with self.fs.open(filename, 'rb') as f:\n",
    "            reader = torchaudio.io.StreamReader(src = f)\n",
    "            reader.add_basic_audio_stream(\n",
    "                frames_per_chunk=self.sample_rate//10,\n",
    "                stream_index=0,\n",
    "                sample_rate=self.sample_rate,\n",
    "            )\n",
    "\n",
    "            audio_tensor = None\n",
    "            for i, waveform in enumerate(reader.stream()):\n",
    "                if audio_tensor is None:\n",
    "                    audio_tensor = waveform[0]\n",
    "                else:\n",
    "                    audio_tensor = torch.cat((audio_tensor, waveform[0]), 0)\n",
    "                \n",
    "                streamed_len = (audio_tensor.shape[0] / self.sample_rate) \n",
    "                if streamed_len >= self.clip_len:\n",
    "                    break # we have enough data\n",
    "               \n",
    "            audio_tensor = audio_tensor.reshape(1, -1) \n",
    "            if audio_tensor.shape[0] > 1:\n",
    "                # the audio has more than 1 channel, convert to mono\n",
    "                audio_tensor = torch.mean(audio_tensor, dim=0).unsqueeze(0)\n",
    "\n",
    "            #num_outputs = 1\n",
    "            #audio_tensor = cast_tuple(audio_tensor, num_outputs)\n",
    "            #data_tuple = tuple((resample(d, sample_hz, target_sample_hz) if exists(target_sample_hz) else d) for d, target_sample_hz in zip(data, self.target_sample_hz))\n",
    "\n",
    "            output = []\n",
    "            audio_length = audio_tensor.size(1)\n",
    "\n",
    "            ## pad or curtail\n",
    "            #max_length = 99999999999999\n",
    "            #if audio_length > max_length:\n",
    "            #    max_start = audio_length - max_length\n",
    "            #    start = torch.randint(0, max_start, (1, ))\n",
    "            #    audio_tensor = audio_tensor[:, start:start + max_length]\n",
    "            #else:\n",
    "            #    audio_tensor = F.pad(audio_tensor, (0, max_length - audio_length), 'constant')\n",
    "\n",
    "            audio_tensor = rearrange(audio_tensor, '1 ... -> ...')\n",
    "            output = audio_tensor.float()\n",
    "\n",
    "            print(self.tick_char, end='', flush=True)\n",
    "            return output\n",
    "\n",
    "    \n",
    "    def __iter__(self):\n",
    "        worker_info = torch.utils.data.get_worker_info()\n",
    "        if worker_info is None:  # single-process data loading, return the full iterator\n",
    "            iter_start = self.start\n",
    "            iter_end = self.end\n",
    "        else:  # in a worker process\n",
    "            # split workload\n",
    "            per_worker = int(math.ceil((self.end - self.start) / float(worker_info.num_workers)))\n",
    "            worker_id = worker_info.id\n",
    "            iter_start = self.start + worker_id * per_worker\n",
    "            iter_end = min(iter_start + per_worker, self.end)\n",
    "\n",
    "        for i in range(iter_start, iter_end):\n",
    "            sample = self.getSample(i)\n",
    "            yield sample\n",
    "\n",
    "# Setup dataloader\n",
    "effects = [\n",
    "    [\"norm\", \"1\"],\n",
    "]\n",
    "\n",
    "needed_clip_len = float(320 * 40)/sample_rate\n",
    "\n",
    "train_subset = music_files[:-1000]\n",
    "val_subset = music_files[-1000:]\n",
    "\n",
    "dst = SeabassIterableDataset(start=0, end=len(train_subset), files=train_subset, \n",
    "                            fs=dataset_fs, effects=effects, clip_len=needed_clip_len)\n",
    "dsv = SeabassIterableDataset(start=0, end=len(val_subset), files=val_subset, \n",
    "                            fs=dataset_fs, effects=effects, clip_len=2.0, tick_char='*')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the sampler\n",
    "#dl_train.sampler\n",
    "#sampler = ds_train.__iter__()\n",
    "#sample = sampler.__next__()\n",
    "#print(sample)\n",
    "#print(waveform1.shape, sr1)\n",
    "#plot_waveform(waveform1, sr1, title=\"Train\", xlim=(-0.1, 3.2))\n",
    "#plot_specgram(waveform1, sr1, title=\"Train\", xlim=(0, 3.04))\n",
    "#Audio(waveform1, rate=sr1)\n",
    "#\n",
    "#_, waveform2, sr2 = ds_val.__iter__()\n",
    "#print(waveform2.shape, sr2)\n",
    "#plot_waveform(waveform2, sr2, title=\"Val\", xlim=(-0.1, 3.2))\n",
    "#plot_specgram(waveform2, sr2, title=\"Val\", xlim=(0, 3.04))\n",
    "#Audio(waveform2, rate=sr2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T7GiyBcBWiZV"
   },
   "source": [
    "### SoundStream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nGU0OZiOwPEO",
    "outputId": "21dd959c-6458-4477-8403-cf810166f38d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................................................................................................0: soundstream total loss: 67.118, soundstream recon loss: 0.084 | discr (scale 1) loss: 2.000 | discr (scale 0.5) loss: 2.001 | discr (scale 0.25) loss: 2.000\n",
      "******0: saving to results\n",
      "0: saving model to results\n",
      "........................................................................................................................1: soundstream total loss: 69.197, soundstream recon loss: 0.071 | discr (scale 1) loss: 1.993 | discr (scale 0.5) loss: 1.996 | discr (scale 0.25) loss: 1.996\n",
      "........................................................................................................................2: soundstream total loss: 67.665, soundstream recon loss: 0.048 | discr (scale 1) loss: 1.993 | discr (scale 0.5) loss: 1.996 | discr (scale 0.25) loss: 1.997\n",
      "........................................................................................................................3: soundstream total loss: 72.337, soundstream recon loss: 0.045 | discr (scale 1) loss: 2.003 | discr (scale 0.5) loss: 2.002 | discr (scale 0.25) loss: 2.002\n",
      "........................................................................................................................4: soundstream total loss: 59.909, soundstream recon loss: 0.036 | discr (scale 1) loss: 2.007 | discr (scale 0.5) loss: 2.003 | discr (scale 0.25) loss: 2.004\n",
      "........................................................................................................................5: soundstream total loss: 62.711, soundstream recon loss: 0.046 | discr (scale 1) loss: 2.008 | discr (scale 0.5) loss: 2.002 | discr (scale 0.25) loss: 2.004\n",
      "........................................................................................................................6: soundstream total loss: 58.209, soundstream recon loss: 0.041 | discr (scale 1) loss: 1.991 | discr (scale 0.5) loss: 1.991 | discr (scale 0.25) loss: 1.995\n",
      "........................................................................................................................7: soundstream total loss: 56.826, soundstream recon loss: 0.045 | discr (scale 1) loss: 1.982 | discr (scale 0.5) loss: 1.985 | discr (scale 0.25) loss: 1.989\n",
      "........................................................................................................................8: soundstream total loss: 65.537, soundstream recon loss: 0.049 | discr (scale 1) loss: 1.954 | discr (scale 0.5) loss: 1.968 | discr (scale 0.25) loss: 1.975\n",
      "........................................................................................................................9: soundstream total loss: 51.912, soundstream recon loss: 0.037 | discr (scale 1) loss: 1.951 | discr (scale 0.5) loss: 1.966 | discr (scale 0.25) loss: 1.975\n",
      "........................................................................................................................10: soundstream total loss: 64.364, soundstream recon loss: 0.045 | discr (scale 1) loss: 1.923 | discr (scale 0.5) loss: 1.945 | discr (scale 0.25) loss: 1.959\n",
      "******10: saving to results\n",
      "........................................................................................................................11: soundstream total loss: 61.327, soundstream recon loss: 0.038 | discr (scale 1) loss: 1.937 | discr (scale 0.5) loss: 1.954 | discr (scale 0.25) loss: 1.970\n",
      "........................................................................................................................12: soundstream total loss: 56.405, soundstream recon loss: 0.035 | discr (scale 1) loss: 1.898 | discr (scale 0.5) loss: 1.930 | discr (scale 0.25) loss: 1.948\n",
      "........................................................................................................................13: soundstream total loss: 53.278, soundstream recon loss: 0.033 | discr (scale 1) loss: 1.858 | discr (scale 0.5) loss: 1.896 | discr (scale 0.25) loss: 1.930\n",
      "........................................................................................................................14: soundstream total loss: 61.605, soundstream recon loss: 0.043 | discr (scale 1) loss: 1.827 | discr (scale 0.5) loss: 1.879 | discr (scale 0.25) loss: 1.914\n",
      "........................................................................................................................15: soundstream total loss: 65.072, soundstream recon loss: 0.048 | discr (scale 1) loss: 1.742 | discr (scale 0.5) loss: 1.818 | discr (scale 0.25) loss: 1.869\n",
      "........................................................................................................................16: soundstream total loss: 59.114, soundstream recon loss: 0.040 | discr (scale 1) loss: 1.662 | discr (scale 0.5) loss: 1.755 | discr (scale 0.25) loss: 1.832\n",
      "........................................................................................................................17: soundstream total loss: 60.530, soundstream recon loss: 0.040 | discr (scale 1) loss: 1.619 | discr (scale 0.5) loss: 1.702 | discr (scale 0.25) loss: 1.810\n",
      "........................................................................................................................18: soundstream total loss: 54.287, soundstream recon loss: 0.038 | discr (scale 1) loss: 1.619 | discr (scale 0.5) loss: 1.694 | discr (scale 0.25) loss: 1.812\n",
      "........................................................................................................................19: soundstream total loss: 47.343, soundstream recon loss: 0.034 | discr (scale 1) loss: 1.499 | discr (scale 0.5) loss: 1.613 | discr (scale 0.25) loss: 1.748\n",
      "........................................................................................................................20: soundstream total loss: 65.875, soundstream recon loss: 0.046 | discr (scale 1) loss: 1.362 | discr (scale 0.5) loss: 1.511 | discr (scale 0.25) loss: 1.694\n",
      "******20: saving to results\n",
      "........................................................................................................................21: soundstream total loss: 52.270, soundstream recon loss: 0.037 | discr (scale 1) loss: 1.333 | discr (scale 0.5) loss: 1.503 | discr (scale 0.25) loss: 1.703\n",
      "........................................................................................................................22: soundstream total loss: 57.786, soundstream recon loss: 0.038 | discr (scale 1) loss: 1.097 | discr (scale 0.5) loss: 1.301 | discr (scale 0.25) loss: 1.575\n",
      "........................................................................................................................23: soundstream total loss: 47.397, soundstream recon loss: 0.026 | discr (scale 1) loss: 0.921 | discr (scale 0.5) loss: 1.094 | discr (scale 0.25) loss: 1.388\n",
      "........................................................................................................................24: soundstream total loss: 61.231, soundstream recon loss: 0.040 | discr (scale 1) loss: 1.024 | discr (scale 0.5) loss: 1.128 | discr (scale 0.25) loss: 1.388\n",
      "........................................................................................................................25: soundstream total loss: 54.287, soundstream recon loss: 0.040 | discr (scale 1) loss: 0.781 | discr (scale 0.5) loss: 0.950 | discr (scale 0.25) loss: 1.223\n",
      "........................................................................................................................26: soundstream total loss: 58.798, soundstream recon loss: 0.038 | discr (scale 1) loss: 0.666 | discr (scale 0.5) loss: 0.769 | discr (scale 0.25) loss: 1.094\n",
      "........................................................................................................................27: soundstream total loss: 66.047, soundstream recon loss: 0.041 | discr (scale 1) loss: 0.743 | discr (scale 0.5) loss: 0.922 | discr (scale 0.25) loss: 1.049\n",
      "........................................................................................................................28: soundstream total loss: 72.649, soundstream recon loss: 0.045 | discr (scale 1) loss: 0.868 | discr (scale 0.5) loss: 0.961 | discr (scale 0.25) loss: 1.052\n",
      "........................................................................................................................29: soundstream total loss: 59.347, soundstream recon loss: 0.036 | discr (scale 1) loss: 0.815 | discr (scale 0.5) loss: 0.766 | discr (scale 0.25) loss: 1.084\n",
      "........................................................................................................................30: soundstream total loss: 63.716, soundstream recon loss: 0.043 | discr (scale 1) loss: 0.578 | discr (scale 0.5) loss: 0.880 | discr (scale 0.25) loss: 0.830\n",
      "******30: saving to results\n",
      "........................................................................................................................31: soundstream total loss: 69.701, soundstream recon loss: 0.045 | discr (scale 1) loss: 0.536 | discr (scale 0.5) loss: 0.856 | discr (scale 0.25) loss: 0.675\n",
      "........................................................................................................................32: soundstream total loss: 56.484, soundstream recon loss: 0.034 | discr (scale 1) loss: 0.448 | discr (scale 0.5) loss: 0.573 | discr (scale 0.25) loss: 0.709\n",
      "........................................................................................................................33: soundstream total loss: 59.281, soundstream recon loss: 0.034 | discr (scale 1) loss: 0.456 | discr (scale 0.5) loss: 0.628 | discr (scale 0.25) loss: 0.774\n",
      "........................................................................................................................34: soundstream total loss: 62.679, soundstream recon loss: 0.035 | discr (scale 1) loss: 0.388 | discr (scale 0.5) loss: 0.789 | discr (scale 0.25) loss: 0.701\n",
      "........................................................................................................................35: soundstream total loss: 56.831, soundstream recon loss: 0.034 | discr (scale 1) loss: 0.499 | discr (scale 0.5) loss: 0.893 | discr (scale 0.25) loss: 0.838\n",
      "........................................................................................................................36: soundstream total loss: 74.549, soundstream recon loss: 0.050 | discr (scale 1) loss: 0.381 | discr (scale 0.5) loss: 0.515 | discr (scale 0.25) loss: 0.554\n",
      "........................................................................................................................37: soundstream total loss: 75.805, soundstream recon loss: 0.045 | discr (scale 1) loss: 0.577 | discr (scale 0.5) loss: 0.562 | discr (scale 0.25) loss: 0.639\n",
      "........................................................................................................................38: soundstream total loss: 72.709, soundstream recon loss: 0.041 | discr (scale 1) loss: 0.308 | discr (scale 0.5) loss: 0.669 | discr (scale 0.25) loss: 0.634\n",
      "........................................................................................................................39: soundstream total loss: 67.142, soundstream recon loss: 0.038 | discr (scale 1) loss: 0.745 | discr (scale 0.5) loss: 0.506 | discr (scale 0.25) loss: 0.527\n",
      "........................................................................................................................40: soundstream total loss: 67.366, soundstream recon loss: 0.044 | discr (scale 1) loss: 1.010 | discr (scale 0.5) loss: 0.449 | discr (scale 0.25) loss: 0.627\n",
      "******40: saving to results\n",
      "........................................................................................................................41: soundstream total loss: 68.280, soundstream recon loss: 0.038 | discr (scale 1) loss: 0.633 | discr (scale 0.5) loss: 0.304 | discr (scale 0.25) loss: 0.404\n",
      "........................................................................................................................42: soundstream total loss: 64.520, soundstream recon loss: 0.041 | discr (scale 1) loss: 0.606 | discr (scale 0.5) loss: 0.395 | discr (scale 0.25) loss: 0.582\n",
      "........................................................................................................................43: soundstream total loss: 68.991, soundstream recon loss: 0.041 | discr (scale 1) loss: 1.026 | discr (scale 0.5) loss: 0.681 | discr (scale 0.25) loss: 0.687\n",
      "........................................................................................................................44: soundstream total loss: 68.810, soundstream recon loss: 0.041 | discr (scale 1) loss: 1.348 | discr (scale 0.5) loss: 0.576 | discr (scale 0.25) loss: 0.697\n",
      "........................................................................................................................45: soundstream total loss: 79.634, soundstream recon loss: 0.048 | discr (scale 1) loss: 1.976 | discr (scale 0.5) loss: 0.773 | discr (scale 0.25) loss: 0.829\n",
      "........................................................................................................................46: soundstream total loss: 63.277, soundstream recon loss: 0.030 | discr (scale 1) loss: 1.618 | discr (scale 0.5) loss: 0.744 | discr (scale 0.25) loss: 0.736\n",
      "........................................................................................................................47: soundstream total loss: 85.612, soundstream recon loss: 0.053 | discr (scale 1) loss: 1.735 | discr (scale 0.5) loss: 0.692 | discr (scale 0.25) loss: 0.623\n",
      ".............................................................................................................."
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 24\u001b[0m\n\u001b[1;32m      6\u001b[0m trainer \u001b[39m=\u001b[39m SoundStreamTrainer(\n\u001b[1;32m      7\u001b[0m     soundstream,\n\u001b[1;32m      8\u001b[0m     \u001b[39m#folder = dataset_folder,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m     num_train_steps \u001b[39m=\u001b[39m \u001b[39m2000\u001b[39m,\n\u001b[1;32m     20\u001b[0m )\u001b[39m.\u001b[39mcuda()\n\u001b[1;32m     21\u001b[0m \u001b[39m# NOTE: I changed num_train_steps to 9 (aka 8 + 1) from 10000 to make things go faster for demo purposes\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[39m# adjusting save_*_every variables for the same reason\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[0;32m/workspaces/audiolm-pytorch/audiolm_pytorch/trainer.py:540\u001b[0m, in \u001b[0;36mSoundStreamTrainer.train\u001b[0;34m(self, log_fn)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain\u001b[39m(\u001b[39mself\u001b[39m, log_fn \u001b[39m=\u001b[39m noop):\n\u001b[1;32m    539\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps \u001b[39m<\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_train_steps:\n\u001b[0;32m--> 540\u001b[0m         logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_step()\n\u001b[1;32m    541\u001b[0m         log_fn(logs)\n\u001b[1;32m    543\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint(\u001b[39m'\u001b[39m\u001b[39mtraining complete\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m/workspaces/audiolm-pytorch/audiolm_pytorch/trainer.py:442\u001b[0m, in \u001b[0;36mSoundStreamTrainer.train_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    439\u001b[0m     multiscale_discr_optim\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m    441\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgrad_accum_every):\n\u001b[0;32m--> 442\u001b[0m     wave, \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdl_iter)\n\u001b[1;32m    443\u001b[0m     wave \u001b[39m=\u001b[39m wave\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m    445\u001b[0m     discr_losses \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msoundstream(\n\u001b[1;32m    446\u001b[0m         wave,\n\u001b[1;32m    447\u001b[0m         apply_grad_penalty \u001b[39m=\u001b[39m apply_grad_penalty,\n\u001b[1;32m    448\u001b[0m         return_discr_loss \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    449\u001b[0m         return_discr_losses_separately \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    450\u001b[0m     )\n",
      "File \u001b[0;32m/workspaces/audiolm-pytorch/audiolm_pytorch/trainer.py:77\u001b[0m, in \u001b[0;36mcycle\u001b[0;34m(dl)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcycle\u001b[39m(dl):\n\u001b[1;32m     76\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m---> 77\u001b[0m         \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m dl:\n\u001b[1;32m     78\u001b[0m             \u001b[39myield\u001b[39;00m data\n",
      "File \u001b[0;32m/opt/conda/envs/audiolm/lib/python3.9/site-packages/accelerate/data_loader.py:584\u001b[0m, in \u001b[0;36mDataLoaderDispatcher.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    580\u001b[0m stop_iteration \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stop_iteration\n\u001b[1;32m    581\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m stop_iteration:\n\u001b[1;32m    582\u001b[0m     \u001b[39m# We may still be at the end of the dataloader without knowing it yet: if there is nothing left in\u001b[39;00m\n\u001b[1;32m    583\u001b[0m     \u001b[39m# the dataloader since the number of batches is a round multiple of the number of processes.\u001b[39;00m\n\u001b[0;32m--> 584\u001b[0m     next_batch, next_batch_info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fetch_batches(main_iterator)\n\u001b[1;32m    585\u001b[0m     \u001b[39m# next_batch_info[0] is None when there are no more batches, otherwise we still need to process them.\u001b[39;00m\n\u001b[1;32m    586\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stop_iteration \u001b[39mand\u001b[39;00m next_batch_info[\u001b[39m0\u001b[39m] \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/envs/audiolm/lib/python3.9/site-packages/accelerate/data_loader.py:519\u001b[0m, in \u001b[0;36mDataLoaderDispatcher._fetch_batches\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    517\u001b[0m     batches \u001b[39m=\u001b[39m []\n\u001b[1;32m    518\u001b[0m     \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mnum_processes):\n\u001b[0;32m--> 519\u001b[0m         batches\u001b[39m.\u001b[39mappend(\u001b[39mnext\u001b[39;49m(iterator))\n\u001b[1;32m    520\u001b[0m     batch \u001b[39m=\u001b[39m concatenate(batches, dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m    521\u001b[0m \u001b[39m# In both cases, we need to get the structure of the batch that we will broadcast on other\u001b[39;00m\n\u001b[1;32m    522\u001b[0m \u001b[39m# processes to initialize the tensors with the right shape.\u001b[39;00m\n\u001b[1;32m    523\u001b[0m \u001b[39m# data_structure, stop_iteration\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/audiolm/lib/python3.9/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/conda/envs/audiolm/lib/python3.9/site-packages/torch/utils/data/dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    676\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 677\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    678\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    679\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/opt/conda/envs/audiolm/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:32\u001b[0m, in \u001b[0;36m_IterableDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m possibly_batched_index:\n\u001b[1;32m     31\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 32\u001b[0m         data\u001b[39m.\u001b[39mappend(\u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset_iter))\n\u001b[1;32m     33\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[1;32m     34\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mended \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[4], line 91\u001b[0m, in \u001b[0;36mSeabassIterableDataset.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     88\u001b[0m     iter_end \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(iter_start \u001b[39m+\u001b[39m per_worker, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mend)\n\u001b[1;32m     90\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(iter_start, iter_end):\n\u001b[0;32m---> 91\u001b[0m     sample \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgetSample(i)\n\u001b[1;32m     92\u001b[0m     \u001b[39myield\u001b[39;00m sample\n",
      "Cell \u001b[0;32mIn[4], line 31\u001b[0m, in \u001b[0;36mSeabassIterableDataset.getSample\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     29\u001b[0m filename \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfiles[index]\n\u001b[1;32m     30\u001b[0m \u001b[39m#data = BytesIO(self.fs.readbytes(filename))\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfs\u001b[39m.\u001b[39;49mopen(filename, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m     32\u001b[0m     reader \u001b[39m=\u001b[39m torchaudio\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mStreamReader(src \u001b[39m=\u001b[39m f)\n\u001b[1;32m     33\u001b[0m     reader\u001b[39m.\u001b[39madd_basic_audio_stream(\n\u001b[1;32m     34\u001b[0m         frames_per_chunk\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msample_rate\u001b[39m/\u001b[39m\u001b[39m/\u001b[39m\u001b[39m10\u001b[39m,\n\u001b[1;32m     35\u001b[0m         stream_index\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m,\n\u001b[1;32m     36\u001b[0m         sample_rate\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msample_rate,\n\u001b[1;32m     37\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/envs/audiolm/lib/python3.9/site-packages/fs/mountfs.py:289\u001b[0m, in \u001b[0;36mMountFS.open\u001b[0;34m(self, path, mode, buffering, encoding, errors, newline, **options)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck()\n\u001b[1;32m    288\u001b[0m fs, _path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_delegate(path)\n\u001b[0;32m--> 289\u001b[0m \u001b[39mreturn\u001b[39;00m fs\u001b[39m.\u001b[39;49mopen(\n\u001b[1;32m    290\u001b[0m     _path,\n\u001b[1;32m    291\u001b[0m     mode\u001b[39m=\u001b[39;49mmode,\n\u001b[1;32m    292\u001b[0m     buffering\u001b[39m=\u001b[39;49mbuffering,\n\u001b[1;32m    293\u001b[0m     encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[1;32m    294\u001b[0m     errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    295\u001b[0m     newline\u001b[39m=\u001b[39;49mnewline,\n\u001b[1;32m    296\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49moptions\n\u001b[1;32m    297\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/envs/audiolm/lib/python3.9/site-packages/fs/base.py:1228\u001b[0m, in \u001b[0;36mFS.open\u001b[0;34m(self, path, mode, buffering, encoding, errors, newline, **options)\u001b[0m\n\u001b[1;32m   1226\u001b[0m validate_open_mode(mode)\n\u001b[1;32m   1227\u001b[0m bin_mode \u001b[39m=\u001b[39m mode\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39mt\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1228\u001b[0m bin_file \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mopenbin(path, mode\u001b[39m=\u001b[39;49mbin_mode, buffering\u001b[39m=\u001b[39;49mbuffering)\n\u001b[1;32m   1229\u001b[0m io_stream \u001b[39m=\u001b[39m iotools\u001b[39m.\u001b[39mmake_stream(\n\u001b[1;32m   1230\u001b[0m     path,\n\u001b[1;32m   1231\u001b[0m     bin_file,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1237\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions\n\u001b[1;32m   1238\u001b[0m )\n\u001b[1;32m   1239\u001b[0m \u001b[39mreturn\u001b[39;00m io_stream\n",
      "File \u001b[0;32m/opt/conda/envs/audiolm/lib/python3.9/site-packages/fs_s3fs/_s3fs.py:603\u001b[0m, in \u001b[0;36mS3FS.openbin\u001b[0;34m(self, path, mode, buffering, **options)\u001b[0m\n\u001b[1;32m    601\u001b[0m s3file \u001b[39m=\u001b[39m S3File\u001b[39m.\u001b[39mfactory(path, _mode, on_close\u001b[39m=\u001b[39mon_close)\n\u001b[1;32m    602\u001b[0m \u001b[39mwith\u001b[39;00m s3errors(path):\n\u001b[0;32m--> 603\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclient\u001b[39m.\u001b[39;49mdownload_fileobj(\n\u001b[1;32m    604\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bucket_name, _key, s3file\u001b[39m.\u001b[39;49mraw, ExtraArgs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdownload_args\n\u001b[1;32m    605\u001b[0m     )\n\u001b[1;32m    606\u001b[0m s3file\u001b[39m.\u001b[39mseek(\u001b[39m0\u001b[39m, os\u001b[39m.\u001b[39mSEEK_SET)\n\u001b[1;32m    607\u001b[0m \u001b[39mreturn\u001b[39;00m s3file\n",
      "File \u001b[0;32m/opt/conda/envs/audiolm/lib/python3.9/site-packages/boto3/s3/inject.py:795\u001b[0m, in \u001b[0;36mdownload_fileobj\u001b[0;34m(self, Bucket, Key, Fileobj, ExtraArgs, Callback, Config)\u001b[0m\n\u001b[1;32m    787\u001b[0m \u001b[39mwith\u001b[39;00m create_transfer_manager(\u001b[39mself\u001b[39m, config) \u001b[39mas\u001b[39;00m manager:\n\u001b[1;32m    788\u001b[0m     future \u001b[39m=\u001b[39m manager\u001b[39m.\u001b[39mdownload(\n\u001b[1;32m    789\u001b[0m         bucket\u001b[39m=\u001b[39mBucket,\n\u001b[1;32m    790\u001b[0m         key\u001b[39m=\u001b[39mKey,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    793\u001b[0m         subscribers\u001b[39m=\u001b[39msubscribers,\n\u001b[1;32m    794\u001b[0m     )\n\u001b[0;32m--> 795\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult()\n",
      "File \u001b[0;32m/opt/conda/envs/audiolm/lib/python3.9/site-packages/s3transfer/futures.py:106\u001b[0m, in \u001b[0;36mTransferFuture.result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    105\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcancel()\n\u001b[0;32m--> 106\u001b[0m     \u001b[39mraise\u001b[39;00m e\n",
      "File \u001b[0;32m/opt/conda/envs/audiolm/lib/python3.9/site-packages/s3transfer/futures.py:103\u001b[0m, in \u001b[0;36mTransferFuture.result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mresult\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m     99\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    100\u001b[0m         \u001b[39m# Usually the result() method blocks until the transfer is done,\u001b[39;00m\n\u001b[1;32m    101\u001b[0m         \u001b[39m# however if a KeyboardInterrupt is raised we want want to exit\u001b[39;00m\n\u001b[1;32m    102\u001b[0m         \u001b[39m# out of this and propagate the exception.\u001b[39;00m\n\u001b[0;32m--> 103\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_coordinator\u001b[39m.\u001b[39;49mresult()\n\u001b[1;32m    104\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    105\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcancel()\n",
      "File \u001b[0;32m/opt/conda/envs/audiolm/lib/python3.9/site-packages/s3transfer/futures.py:261\u001b[0m, in \u001b[0;36mTransferCoordinator.result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Waits until TransferFuture is done and returns the result\u001b[39;00m\n\u001b[1;32m    252\u001b[0m \n\u001b[1;32m    253\u001b[0m \u001b[39mIf the TransferFuture succeeded, it will return the result. If the\u001b[39;00m\n\u001b[1;32m    254\u001b[0m \u001b[39mTransferFuture failed, it will raise the exception associated to the\u001b[39;00m\n\u001b[1;32m    255\u001b[0m \u001b[39mfailure.\u001b[39;00m\n\u001b[1;32m    256\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    257\u001b[0m \u001b[39m# Doing a wait() with no timeout cannot be interrupted in python2 but\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[39m# can be interrupted in python3 so we just wait with the largest\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[39m# possible value integer value, which is on the scale of billions of\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[39m# years...\u001b[39;00m\n\u001b[0;32m--> 261\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_done_event\u001b[39m.\u001b[39;49mwait(MAXINT)\n\u001b[1;32m    263\u001b[0m \u001b[39m# Once done waiting, raise an exception if present or return the\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[39m# final result.\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n",
      "File \u001b[0;32m/opt/conda/envs/audiolm/lib/python3.9/threading.py:581\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    579\u001b[0m signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flag\n\u001b[1;32m    580\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 581\u001b[0m     signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cond\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    582\u001b[0m \u001b[39mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/opt/conda/envs/audiolm/lib/python3.9/threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    311\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 312\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    313\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    314\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "soundstream = SoundStream(\n",
    "    codebook_size = 1024,\n",
    "    rq_num_quantizers = 8,\n",
    ")\n",
    "\n",
    "trainer = SoundStreamTrainer(\n",
    "    soundstream,\n",
    "    #folder = dataset_folder,\n",
    "    #train_dataloader=dl_train,\n",
    "    #val_dataloader=dl_val,\n",
    "    train_dataset=dst,\n",
    "    val_dataset=dsv,\n",
    "    #lr = 0.001,\n",
    "    batch_size = 6,\n",
    "    grad_accum_every = 10,         # effective batch size of 32\n",
    "    data_max_length = 320 * 32,\n",
    "    save_results_every = 10,\n",
    "    save_model_every = 100,\n",
    "    num_train_steps = 2000,\n",
    ").cuda()\n",
    "# NOTE: I changed num_train_steps to 9 (aka 8 + 1) from 10000 to make things go faster for demo purposes\n",
    "# adjusting save_*_every variables for the same reason\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QoHgkgA3XKXH"
   },
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rzghrux5WinW",
    "outputId": "9dd39f7f-0046-4a5f-826e-a442345987af"
   },
   "outputs": [],
   "source": [
    "# Everything together\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4rQPHTSRngEr"
   },
   "outputs": [],
   "source": [
    "output_path = \"out.wav\"\n",
    "sample_rate = 44100\n",
    "torchaudio.save(output_path, generated_wav.cpu(), sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "is9wLY_ncDYK"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
